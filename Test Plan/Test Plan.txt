Test Plan Report: Hackathon Research Hub

1. Objective
  -The goal of this test plan is to validate the core functionalities of the Hackathon Research Hub platform, including the user registration, user login, hackathon experience sharing, research experience sharing, JWT authentication, and overall user experience. 
  -The platform will be tested to ensure it works across multiple devices and browsers while meeting performance, security, and usability standards.
  -Testing will be performed manually to check for any bugs or functionality issues, with the ultimate goal of providing a stable, user-friendly platform.


2. Scope
  This test plan covers the following areas:

  -Functional Testing: 
    Verifying login, registration, hackathon experience sharing, research experience sharing.

  -UI Testing: 
    Ensuring proper layout, design, and responsiveness across browsers and devices.

  -Security Testing: 
    Ensuring JWT token-based authentication and Google authentication is secure and functioning.

  -Performance Testing: 
    Evaluating the platform's performance under typical and high load conditions.

  -Regression Testing: 
    Ensuring new changes do not break existing functionality.

  -Usability Testing : 
    Ensuring that users can navigate between pages seamlessly.

  -Out of Scope:
    -Backend API testing (unless specifically requested).
    -Stress testing of server infrastructure.


3. Test Strategy

  -Manual Testing: 
    Perform exploratory testing for critical user flows such as login, research experience upload, and hackathon experience sharing functionality.

  -API Testing:
    Use Postman for testing APIs. Verify that API endpoints for user authentication, research paper uploads, and hackathon experience sharing are functioning correctly. Ensure that APIs return expected responses, handle errors properly, and meet performance expectations.

  -Automation Testing: 
    Use Selenium for automation of regression tests for key user workflows (if applicable).

  -Performance Testing: 
    Utilize JMeter to simulate multiple users and check for performance bottlenecks.

  -Security Testing: 
    Focus on testing for vulnerabilities in authentication mechanisms, especially JWT security.

  -Cross-Browser Testing: 
    Test the platformâ€™s compatibility across the latest versions of Chrome, Firefox, Safari, and Edge.


4. Test Environments

  -Browsers: Chrome, Firefox, Safari, Edge.

  -Devices: Windows 10 (desktop), iOS (mobile), Android (mobile).

  -Testing Tools:
    -JIRA: For defect tracking.
    -Postman: For basic API testing.
    -Selenium: For automation of user flows.
    -JMeter: For performance testing.


5. Test Schedule

  -Test Case Design & Review: Date 1

  -Test Execution: Date 2

  -Defect Reporting & Resolution: Date 3

  -Test Closure: Date 4


6. Defect Reporting and Tracking

  1. Defect Identification: 
    A defect is identified when functionality deviates from the expected behavior.

  2. Defect Reporting:
    Use a simple defect template with:
      -Title: Brief description of the issue.
      -Steps to reproduce: Detailed steps.
      -Expected behavior: What should happen.
      -Actual behavior: What is happening.
      -Severity: Low/Medium/High.
      -Screenshot or logs: Attach images (such as your login -page error screenshots).

  3. Defect Tracking:
    Track defects in a project management tool Jira.

  4. Severity Levels:

    -Critical (Application crash or login failure)
    -Major (Functionality not working as expected but not critical)
    -Minor (UI issues or non-critical bugs)


7. Risk and Mitigation

  - Risk: Testing may be delayed due to the unavailability of the backend server.

  - Mitigation: Schedule testing during off-peak hours, or use mock services to simulate backend interactions.

  - Risk: Browser or device-specific UI issues.

  - Mitigation: Use responsive design testing tools and ensure compatibility testing across all major browsers.


8. Approval
  Test plan, test cases, and defect reports will be reviewed and approved by the project stakeholders before execution.


9. Exit Criteria

  Testing will be considered complete when:

    -All critical defects have been resolved or deferred.
    -All planned test cases have been executed.
    -Test results have been documented and shared with stakeholders.
